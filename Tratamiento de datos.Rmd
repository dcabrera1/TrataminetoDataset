---
title: "Tratamiento de datos"
author: "Autores: Paula Rodríguez & David Cabrera"
date: "Mayo 2020"
output:
  github_document: default
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
  word_document: default
  pdf_document:
    highlight: zenburn
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


******
# Introducción
******
El conjunto de datos se acredita a Ronny Kohavi y Barry Becker y se extrajo de los datos de la Oficina del Censo de los Estados Unidos de 1994 e implica el uso de datos personales como el nivel de educación para predecir si un individuo ganará más o menos de $ 50,000 por año.


## Objetivos
Determinar los factores que inciden para que una persona gane más de 50K


******
# Solución 
******


## Compresión de los datos

Se trabajará con el dataset Adult que se obtuvo del siguiente enlace: http://archive.ics.uci.edu/ml/datasets/Adult. 

La base de datos Adult tiene 48840 observaciones y 15 variables, las cuales se detallan a continuación: 

* age: Edad de la persona [Entero mayor que cero]

* workclass: Un término general para representar la situación laboral de un individuo, que se clasifica en: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked. 

* fnlwgt (peso final): Es el número de personas que el censo cree que representa a la población. 

* education: El nivel más alto de educación alcanzado por una persona, puede ser: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool. 

* education-num: El nivel más alto de educación alcanzado en forma numérica.

* marital-status: Estado civil de las personas, se tiene: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse. Married-civ-spouse corresponde a un cónyuge civil, mientras que Married-AF-spouse corresponde a un cónyuge de las Fuerzas Armadas. 

* occupation: El tipo general de ocupación de las personas, se tiene: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces. 

* relationship: Representa la relación del individio, se tiene: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried. 

* race: Raza de la persona, se tiene: Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black. 

* sex: El sexo biológico del individuo, se tiene: Hombre / Mujer.

* capital-gain: Representa el capital ganado del individuo. 

* capital-loss: Pérdida de capital de un individuo. 

* hours-per-week: Las horas que una persona ha reportado de su trabajo por semana. 

* native-country: País de origen de la persona, puede ser: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands. 

* income: Si una persona gana más de 50K o no, se tiene: <=50K / >50K. 


Los datos se encuentran en 2 archivos: adult.data y adult.test que suman el 100% de observaciones, la documentación indica que el archivo adult.data tiene 2/3 de los datos y el archivo de adult.test tiene 1/3 de los datos. 


## Extracción 

```{r message= FALSE, warning=FALSE}
# Cargamos los paquetes R que vamos a usar
library(ggplot2)
library(dplyr)
# Cargamos el juego de datos
test <- read.csv('adult-test.csv',stringsAsFactors = FALSE)
train <- read.csv('adult-train.csv', stringsAsFactors = FALSE)
#Agrego los nombres de las columas de test y train, ya que al agregar luego de unir los df, me generó error
train <- setNames(train, c("age","workclass","fnlwgt","education","education-num","marital-status","occupation","relationship","race","sex","capital-gain","capital-loss","hours-per-week","native-country","income"))
test <- setNames(test, c("age","workclass","fnlwgt","education","education-num","marital-status","occupation","relationship","race","sex","capital-gain","capital-loss","hours-per-week","native-country","income"))
# Unimos los dos conjuntos de datos en uno solo dataset, de tal forma de tener la totalidad de datos
adultData <- bind_rows(train,test)
```



```{r message= FALSE, warning=FALSE}
# Verificamos la estructura del conjunto de datos
str(adultData)
# Estadística descriptiva
summary(adultData)
```

## Tratamiento de los datos

```{r message= FALSE, warning=FALSE}
#Elimino las variables que no se consideran para correr el modelo
adultData <- adultData[, -c(3,4,8,11,12,14)]
#Elimino los puntos "." de la columna income del dataframe que ingresaron del conjunto de datos de test
adultData$income = as.character(gsub("\\.", "", adultData$income))
```


```{r message= FALSE, warning=FALSE}
library(modeest) # Para utilizar la moda
#Estadísticas de valores nulos
colSums(is.na(adultData))
#Estadísticas de valores vacíos
colSums(adultData=="")
colSums(adultData==" ?")
#Reemplazo las incógnitas por valores vacíos para aplicar la imputación
adultData$workclass[adultData$workclass==" ?"]<- NA
adultData$occupation[adultData$occupation==" ?"]<- NA
#Las variables workclass y occupation tienen valores vacíos (NA), corresponden a un 5% de los datos, tranquilamente se pueden eliminar, sin embargo, se emplea el método de imputación de valores basado en la similitud o diferencia entre los registros, la imputación basada en k vecinos más próximos (en inglés, kNN-imputation). Se emplea este método de imputación bajo la hipótesis de que nuestros datos guardan cierta relación.
#install.packages('VIM')
library(VIM)
adultData$workclass <- kNN(adultData)$workclass
adultData$occupation <- kNN(adultData)$occupation
#Aplico nuevamente la estadísticas de valores vacíos
colSums(adultData==" ?")
```

```{r message= FALSE, warning=FALSE}
# ¿Con qué variables tendría sentido un proceso de discretización?
apply(adultData,2, function(x) length(unique(x)))
# Discretizamos las variables con pocas clases (sex, income)
cols<-c("workclass","marital-status","occupation", "race", "sex", "income")
for (i in cols){
  adultData[,i] <- as.factor(adultData[,i])
}
```

```{r message= FALSE, warning=FALSE}
# Guardo el nuevo dataset con los datos listos para correr el modelo
write.csv(adultData,"adultData.csv", row.names = T)
```

```{r message= FALSE, warning=FALSE}
# Valores extremos
# Los valores atípicos corresponden a un 0,3%, que no influyen en el modelo
boxplot(adultData[,1], main='Edad')
# Los valores atípicos corresponden a un 3,43%, se va a trabajar con todo los datos debido a que corresponden a la población de EEUU, donde la gente tiene más de un trabajo y a la semana 
#tranquilamente pueden trabajar 100 horas
boxplot(adultData[,8], main='horas por semana')
boxplot(adultData[,3], main='Educación')
#Filtro únicamente los datos para clasificar la información en trabajadores públicos, privados, independientes y otros. 
adultPublicWorker<-adultData[which(adultData$workclass== ' Federal-gov'|adultData$workclass== ' Local-gov'|adultData$workclass== ' State-gov'),]
adultPrivateWorker<-adultData[which(adultData$workclass== ' Private'|adultData$workclass== ' Local-gov'),]
adultSelfWorker<-adultData[which(adultData$workclass== ' Self-emp-not-inc'|adultData$workclass== 'Self-emp-inc'),]
adultSelfWorker<-adultData[which(adultData$workclass== ' Never-worked'&adultData$workclass== ' Without-pay'),]
```


```{r message= FALSE, warning=FALSE}
library("dplyr")
library("ggplot2")
# Comprobación de la normalidad 
par(mfrow=c(2,2))
for(i in 1:ncol(adultData)) {
if (is.numeric(adultData[,i])){
qqnorm(adultData[,i],main = paste("Normal Q-Q Plot for ",colnames(adultData)[i]))
qqline(adultData[,i],col="red")
hist(adultData[,i],
main=paste("Histogram for ", colnames(adultData)[i]),
xlab=colnames(adultData)[i], freq = FALSE)
}
}
```

```{r message= FALSE, warning=FALSE}
#Comprobación de la homogeneidad de la varianza
fligner.test(adultData$`education-num` ~ income, data = adultData)
```




```{r echo=TRUE, message=FALSE, warning=FALSE}
library(ggplot2)
library(dplyr)
#Se comprueba la homogeneidad de la varianza de las variables ingresos y edad
data("adultData")
age <- filter(.data = adultData, income %in% c("<=50K", ">50K"))
ggplot(data = adultData, aes(x = income, y = age, colour = income)) +
  geom_boxplot() +
  geom_point() +
  theme_bw() +
  theme(legend.position = "none")
aggregate(age~income, data = adultData, FUN = var)
```

Se puede ver que gran parte de los que ganan menos o igual a 50K se encuentran entre las edades de 25 y 40 años teniendo la media en los 28 años y con respecto a los que ganan mas de 50K se encuentran en las edades entre 29 y 51 años teniendo la media en 45 años.

```{r echo=TRUE, message=FALSE, warning=FALSE}
#Se aplica el test Brown-Forysth que es equivalente al test de Levene cuando se emplea la mediana como medida de centralidad ya que permite comparar los ingresos contra las edades con los diferentes estadisticos de centralidad entre los cuales se encuentran la media, mediana y media truncada 
#install.packages("HH")
library(HH)
hov(adultData$age ~ adultData$income)
```
```{r echo=TRUE, message=FALSE, warning=FALSE}
#Se comprueba la normalidad y homogeneidad de la varianza de las variables ingresos y horas por semana
data("adultData")
age <- filter(.data = adultData, income %in% c("<=50K", ">50K"))
ggplot(data = adultData, aes(x = income, y = adultData$`hours-per-week`, colour = income)) +
  geom_boxplot() +
  geom_point() +
  theme_bw() +
  theme(legend.position = "none")
aggregate(adultData$`hours-per-week`~income, data = adultData, FUN = var)
```
Se puede ver que gran parte de los que ganan menos o igual a 50K se encuentran entre los que trabajan de 30 a 35 horas por semana teniendo la media en las 35 horas y con respecto a los que ganan mas de 50K se encuentran entre los que trabajan de 35 a 50 horas por semana teniendo la media en 35 horas.
```{r echo=TRUE, message=FALSE, warning=FALSE}
#Se aplica el test Brown-Forysth que es equivalente al test de Levene cuando se emplea la mediana como medida de centralidad ya que permite comparar los ingresos contra las edades con los diferentes estadisticos de centralidad entre los cuales se encuentran la media, mediana y media truncada 
#install.packages("HH")
library(HH)
hov(adultData$`hours-per-week` ~ adultData$income)
```


```{r echo=TRUE, message=FALSE, warning=FALSE}
# Se corre el modelo de regresión logística
modelo.logit <- glm(income ~ age + workclass + `education-num`+`marital-status`+occupation+race+sex+`hours-per-week`, 
                    data = adultData, family = "binomial")
summary(modelo.logit)
        
```

```{r echo=TRUE, message=FALSE, warning=FALSE}
library(caret)
adultData$income <- ifelse(adultData$income==' <=50K',1,0)
dmy <- dummyVars(" ~ .", data = adultData)
adultTrsf <- data.frame(predict(dmy, newdata = adultData))
#Genera la matriz de correlación
cor.prob <- function (X, dfr = nrow(X) - 2) {
  R <- cor(X, use="pairwise.complete.obs")
  above <- row(R) < col(R)
  r2 <- R[above]^2
  Fstat <- r2 * dfr/(1 - r2)
  R[above] <- 1 - pf(Fstat, 1, dfr)
  R[row(R) == col(R)] <- NA
  R
}
#Presenta la matriz de correlación de 4 columnas con filas/indices, correlacion, p-value 
flattenSquareMatrix <- function(m) {
  if( (class(m) != "matrix") | (nrow(m) != ncol(m))) stop("Must be a square matrix.")
  if(!identical(rownames(m), colnames(m))) stop("Row and column names must be equal.")
  ut <- upper.tri(m)
  data.frame(i = rownames(m)[row(m)[ut]],
             j = rownames(m)[col(m)[ut]],
             cor=t(m)[ut],
             p=m[ut])
}
#Corro la correlación al dataset
corMasterList <- flattenSquareMatrix (cor.prob(adultTrsf))
print(head(corMasterList,10))
#Ordeno la matriz de correlación por valor
corList <- corMasterList[order(corMasterList$cor),]
#Obtengo las correlaciones más significativas
selectedSub <- subset(corList, (abs(cor) > 0.2 & j == 'income'))
bestSub <-  sapply(strsplit(as.character(selectedSub$i),'[.]'), "[", 1)
# Las variables de alta correlación son: edad, sexo, ocupación
        
```


```{r echo=TRUE, message=FALSE, warning=FALSE}
#pruebas de contraste de hipotesis con el test de Mann Whitney 
#Queremos probar (nuestra hipótesis alternativa) si la proporción de horas trabajadas con los ingresos es >50K. Por lo tanto, tenemos que: Hipótesis nula es H0:p≤50, Hipótesis alternativa es H1:p>50

wilcox.test(adultData$income,adultData$`hours-per-week`,paired=FALSE,conf.level=0.95)
 
```
Con un p-value < 2.2e-16 menor a 0.05 se aprueba la hipótesis nula H0.Por lo tanto, podemos concluir que la probabilidad de que una persona gane mas de 50K trabajando 35 horas es de un 70% y si influye la proporción de horas trabajadas con los ingresos.

```{r echo=TRUE, message=FALSE, warning=FALSE}
#pruebas de contraste de hipotesis con el test de Mann Whitney
#Queremos probar (nuestra hipótesis alternativa) si la proporción de edad con los ingresos es ≤50K. Por lo tanto, tenemos que: Hipótesis nula es H0:p>50, Hipótesis alternativa es H1:p≤50

wilcox.test(adultData$income,adultData$age,paired=FALSE,conf.level=0.95)
```
Con un p-value < 2.2e-16 menor a 0.05 se aprueba la hipótesis nula H0.Por lo tanto, podemos concluir que la probabilidad de que una persona gane mas de 50K teniendo 25 años es de un 48% y si influye la edad con los ingresos.